# ğŸŒ¦ï¸ AWS Serverless Data Lake (End-to-End)

![AWS](https://img.shields.io/badge/AWS-Cloud-232F3E?style=for-the-badge&logo=amazon-aws&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.12-blue?style=for-the-badge&logo=python&logoColor=white)
![Lambda](https://img.shields.io/badge/Lambda-Serverless-FF9900?style=for-the-badge&logo=aws-lambda&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-Data_Wrangling-150458?style=for-the-badge&logo=pandas&logoColor=white)
![Athena](https://img.shields.io/badge/Athena-SQL_Analytics-blueviolet?style=for-the-badge&logo=amazonaws&logoColor=white)

![Diagrama](docs/architecture/evidence_diagram.png)

Este projeto Ã© um **Data Lakehouse** completo e *serverless* construÃ­do na AWS. O pipeline realiza a ingestÃ£o de dados meteorolÃ³gicos em tempo real via API, processa e refina as informaÃ§Ãµes utilizando Python (Pandas) e disponibiliza os dados para Analytics via SQL (Athena), seguindo a **Arquitetura MedalhÃ£o**.

---

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

O projeto utiliza uma arquitetura orientada a eventos (**Event-Driven**) para garantir baixo custo e processamento em tempo real.

![Estrutura do Data Lake S3](docs/architecture/evidence_s3_structure.png)

1.  **IngestÃ£o (Extract - Bronze Layer):**
    * **AWS Lambda (`IngestWeather`):** Consumo da API OpenWeatherMap.
    * **Timezone Aware:** Tratamento de fuso horÃ¡rio (UTC -> BRT) para particionamento correto.
    * **Storage:** Armazenamento do JSON bruto no **Amazon S3** (`/bronze`).
2.  **TransformaÃ§Ã£o (Transform - Silver Layer):**
    * **Gatilho AutomÃ¡tico:** O upload na camada Bronze dispara o prÃ³ximo Lambda (S3 Event Notifications).

    ![Lambda S3 Trigger](docs/architecture/evidence_lambda_trigger.png)

    * **AWS Lambda (`ProcessWeather`):** Processamento robusto com **Pandas** (via Lambda Layer).
    * **Flattening:** ConversÃ£o de JSONs aninhados para estrutura tabular.
    * **OtimizaÃ§Ã£o:** ConversÃ£o para formato colunar **Parquet** (compressÃ£o Snappy) e higienizaÃ§Ã£o de nomes de colunas.
3.  **Analytics (Load/Serve - Gold Layer):**
    * **Amazon Athena:** Tabela externa mapeada sobre os arquivos Parquet.
    * **Serverless SQL:** Consultas *Ad-hoc* sem necessidade de servidores de banco de dados.

---

## ğŸš€ Como Executar

### PrÃ©-requisitos
* Conta na [AWS](https://aws.amazon.com/) (Free Tier elegÃ­vel).
* Chave de API da [OpenWeatherMap](https://openweathermap.org/).
* [Python 3.x](https://www.python.org/) instalado.

### 1. ConfiguraÃ§Ã£o de Infraestrutura (AWS Console)
1.  Crie um **Bucket S3** (ex: `datalake-clima-seu-nome`).
2.  Crie uma **IAM Role** com permissÃµes de leitura/escrita no S3 e execuÃ§Ã£o de Lambda.
3.  Configure as FunÃ§Ãµes Lambda com o cÃ³digo disponÃ­vel na pasta `/src`.

### 2. ConfiguraÃ§Ã£o de VariÃ¡veis de Ambiente
Nos Lambdas, configure as seguintes variÃ¡veis de ambiente (Environment Variables) para seguranÃ§a (evitando senhas no cÃ³digo):

```env
OPENWEATHER_API_KEY='sua_chave_da_api'
BUCKET_NAME='nome-do-seu-bucket-s3'
CITY_NAME='Montes Claros'
```

## ğŸš€ 3. Deploy e ExecuÃ§Ã£o

Como Ã© uma arquitetura **serverless**, o deploy Ã© feito atualizando os cÃ³digos nas funÃ§Ãµes **AWS Lambda**.

### â–¶ï¸ Como iniciar o fluxo

VocÃª pode iniciar o pipeline de duas formas:

- Executar um teste manual na funÃ§Ã£o **IngestWeather** (botÃ£o **Test** no console da AWS)
- Configurar um **Amazon EventBridge Scheduler** para rodar automaticamente a cada hora

---

## ğŸ“Š Estrutura de AnÃ¡lise (SQL Athena)

ApÃ³s o processamento, os dados ficam disponÃ­veis no **Amazon Athena** atravÃ©s da tabela:

### ğŸ—„ï¸ `tbl_clima`

| Coluna           | DescriÃ§Ã£o                                                                 |
|------------------|---------------------------------------------------------------------------|
| `name`          | Nome da cidade coletada                                                   |
| `main_temp`    | Temperatura atual (Â°C)                                                   |
| `main_humidity`| Umidade relativa do ar (%)                                               |
| `ingestion_date` | Timestamp exato da coleta                                              |
| `partition`    | Particionamento Hive (ano, mÃªs, dia) para otimizaÃ§Ã£o de queries         |

---

## ğŸ“ˆ VisualizaÃ§Ã£o (Analytics Results)

Aqui estÃ¡ um exemplo de consulta SQL exploratÃ³ria executada diretamente no Athena, consumindo os dados da camada **Silver (Parquet)**:

![Resultado da Query no Athena](docs/architecture/evidence_gold_analytics.png)

### ğŸ” Query de Exemplo

```sql
SELECT 
    name, 
    main_temp, 
    main_humidity, 
    from_unixtime(dt) 
FROM db_clima_fagner.tbl_clima 
WHERE main_temp > 20 
ORDER BY ingestion_date DESC;
```

## ğŸ”® Roadmap e Melhorias Futuras

Este projeto implementa uma arquitetura robusta (**MVP**), mas hÃ¡ espaÃ§o para evoluÃ§Ã£o rumo a um cenÃ¡rio **Enterprise (v2.0)**:

### ğŸ—ï¸ Infraestrutura como CÃ³digo (IaC)
- Substituir a criaÃ§Ã£o manual no console por **Terraform** ou **AWS SAM**
- Permitir versionamento e reprodutibilidade da infraestrutura

### ğŸ“Š VisualizaÃ§Ã£o de Dados (BI)
- Conectar o **Amazon QuickSight** ao **Athena**
- Criar dashboards dinÃ¢micos de variaÃ§Ã£o de temperatura e alertas meteorolÃ³gicos

### ğŸ” Observabilidade
- Configurar **CloudWatch Alarms**
- NotificaÃ§Ãµes por e-mail em caso de falha ou timeout nas funÃ§Ãµes Lambda

### ğŸ”„ CI/CD
- Implementar **GitHub Actions**
- Deploy automÃ¡tico dos cÃ³digos Python na AWS a cada push na branch `main`

---

## ğŸ“ Contato

**Fagner Rezende**  
Engenharia de Dados | Python | SQL | ETL | Analytics  

ğŸ“§ Email: fagner_rezende@hotmail.com  
ğŸ’¼ LinkedIn: [https://www.linkedin.com/in/fagnerabrezende](https://www.linkedin.com/in/fagnerabrezende)  
ğŸ™ GitHub: [https://github.com/Fagner-rezende](https://github.com/Fagner-rezende)
